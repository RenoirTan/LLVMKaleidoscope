<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Types that converts a file into a list of tokens."><meta name="keywords" content="rust, rustlang, rust-lang, tokenizer"><title>kaleidoscope_lexer::tokenizer - Rust</title><link rel="stylesheet" type="text/css" href="../../normalize.css"><link rel="stylesheet" type="text/css" href="../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" type="text/css" href="../../light.css"  id="themeStyle"><link rel="stylesheet" type="text/css" href="../../dark.css" disabled ><link rel="stylesheet" type="text/css" href="../../ayu.css" disabled ><script id="default-settings"></script><script src="../../storage.js"></script><script src="../../crates.js"></script><noscript><link rel="stylesheet" href="../../noscript.css"></noscript><link rel="icon" type="image/svg+xml" href="../../favicon.svg">
<link rel="alternate icon" type="image/png" href="../../favicon-16x16.png">
<link rel="alternate icon" type="image/png" href="../../favicon-32x32.png"><style type="text/css">#crate-search{background-image:url("../../down-arrow.svg");}</style></head><body class="rustdoc mod"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="sidebar-menu" role="button">&#9776;</div><a href='../../kaleidoscope_lexer/index.html'><div class='logo-container rust-logo'><img src='../../rust-logo.png' alt='logo'></div></a><h2 class="location">Module tokenizer</h2><div class="sidebar-elems"><div class="block items"><ul><li><a href="#modules">Modules</a></li><li><a href="#structs">Structs</a></li></ul></div><div id="sidebar-vars" data-name="tokenizer" data-ty="mod" data-relpath="./"></div><script defer src="./sidebar-items.js"></script></div></nav><div class="theme-picker"><button id="theme-picker" aria-label="Pick another theme!" aria-haspopup="menu" title="themes"><img src="../../brush.svg" width="18" height="18" alt="Pick another theme!"></button><div id="theme-choices" role="menu"></div></div><nav class="sub"><form class="search-form"><div class="search-container"><div><select id="crate-search"><option value="All crates">All crates</option></select><input class="search-input" name="search" disabled autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"></div><button type="button" id="help-button" title="help">?</button><a id="settings-menu" href="../../settings.html" title="settings"><img src="../../wheel.svg" width="18" height="18" alt="Change settings"></a></div></form></nav><section id="main" class="content"><h1 class="fqn"><span class="in-band">Module <a href="../index.html">kaleidoscope_lexer</a>::<wbr><a class="mod" href="#">tokenizer</a><button id="copy-path" onclick="copy_path(this)" title="copy path"><img src="../../clipboard.svg" width="19" height="18" alt="Copy item import" title="Copy item import to clipboard"></button></span><span class="out-of-band"><span id="render-detail"><a id="toggle-all-docs" href="javascript:void(0)" title="collapse all docs">[<span class="inner">&#x2212;</span>]</a></span><a class="srclink" href="../../src/kaleidoscope_lexer/tokenizer/mod.rs.html#1-15" title="goto source code">[src]</a></span></h1><details class="rustdoc-toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>Types that converts a file into a list of tokens.</p>
<p>See also <a href="tokenizer/struct.Tokenizer.html" title="crate::tokenizer::Tokenizer"><code>crate::tokenizer::Tokenizer</code></a></p>
</div></details><h2 id="modules" class="section-header"><a href="#modules">Modules</a></h2>
<table><tr class="module-item"><td><a class="mod" href="filestream/index.html" title="kaleidoscope_lexer::tokenizer::filestream mod">filestream</a></td><td class="docblock-short"><p>A special structure which iterates over the characters in a file. It has
special functions to ensure smooth traversal through a file or any
sequence that can be iterated over.</p>
</td></tr><tr class="module-item"><td><a class="mod" href="lexerser/index.html" title="kaleidoscope_lexer::tokenizer::lexerser mod">lexerser</a></td><td class="docblock-short"><p>A module for serialising a tokeniser. This only exists so I can convert
a Kaleidoscope programme into a JSON file.</p>
</td></tr><tr class="module-item"><td><a class="mod" href="lexertuple/index.html" title="kaleidoscope_lexer::tokenizer::lexertuple mod">lexertuple</a></td><td class="docblock-short"><p>Some tuples storing a <a href="filestream/struct.FileStream.html" title="FileStream"><code>FileStream</code></a> and a <a href="tokenizer/struct.Tokenizer.html" title="Tokenizer"><code>Tokenizer</code></a>.</p>
</td></tr><tr class="module-item"><td><a class="mod" href="tokenizer/index.html" title="kaleidoscope_lexer::tokenizer::tokenizer mod">tokenizer</a></td><td class="docblock-short"><p>A struct that reads a file and creates tokens from them.</p>
</td></tr><tr class="module-item"><td><a class="mod" href="tokiter/index.html" title="kaleidoscope_lexer::tokenizer::tokiter mod">tokiter</a></td><td class="docblock-short"><p>A module defining a <a href="tokiter/struct.TokenIterator.html" title="TokenIterator"><code>TokenIterator</code></a> that can continually read a file
stream and spit out tokens in a for loop.</p>
</td></tr></table><h2 id="structs" class="section-header"><a href="#structs">Structs</a></h2>
<table><tr class="module-item"><td><a class="struct" href="struct.FileStream.html" title="kaleidoscope_lexer::tokenizer::FileStream struct">FileStream</a></td><td class="docblock-short"><p>A file stream which returns a unicode codepoint one at a time.
This is in contrast to a normal <a href="https://doc.rust-lang.org/1.54.0/std/fs/struct.File.html" title="std::fs::File"><code>std::fs::File</code></a> which can only read
bytes to an array.</p>
</td></tr><tr class="module-item"><td><a class="struct" href="struct.LexerSerializer.html" title="kaleidoscope_lexer::tokenizer::LexerSerializer struct">LexerSerializer</a></td><td class="docblock-short"><p>Serialises a <a href="tokiter/struct.TokenIterator.html" title="TokenIterator"><code>TokenIterator</code></a> into a list of tokens.</p>
</td></tr><tr class="module-item"><td><a class="struct" href="struct.LexerTupleMut.html" title="kaleidoscope_lexer::tokenizer::LexerTupleMut struct">LexerTupleMut</a></td><td class="docblock-short"><p>A tuple storing mutable references to a <a href="filestream/struct.FileStream.html" title="FileStream"><code>FileStream</code></a> and a <a href="tokenizer/struct.Tokenizer.html" title="Tokenizer"><code>Tokenizer</code></a>.
Both of these objects can be used to create a stream of tokens.</p>
</td></tr><tr class="module-item"><td><a class="struct" href="struct.LexerTupleRef.html" title="kaleidoscope_lexer::tokenizer::LexerTupleRef struct">LexerTupleRef</a></td><td class="docblock-short"><p>A tuple storing immutable references to a <a href="filestream/struct.FileStream.html" title="FileStream"><code>FileStream</code></a> and a
<a href="tokenizer/struct.Tokenizer.html" title="Tokenizer"><code>Tokenizer</code></a>. This is basically useless because you need to be able to
mutate both the stream and the tokenizer to create tokens. In order to
use that functionality, please see <a href="lexertuple/struct.LexerTupleMut.html" title="LexerTupleMut"><code>LexerTupleMut</code></a>.</p>
</td></tr><tr class="module-item"><td><a class="struct" href="struct.TokenIterator.html" title="kaleidoscope_lexer::tokenizer::TokenIterator struct">TokenIterator</a></td><td class="docblock-short"><p>A structure that takes a <a href="filestream/struct.FileStream.html" title="FileStream"><code>FileStream</code></a> and reads the characters to produce
one token for each iteration in a for loop.</p>
</td></tr><tr class="module-item"><td><a class="struct" href="struct.Tokenizer.html" title="kaleidoscope_lexer::tokenizer::Tokenizer struct">Tokenizer</a></td><td class="docblock-short"><p>The tokeniser which iterates over the characters in a file stream and
yields a stream of tokens.</p>
</td></tr></table></section><section id="search" class="content hidden"></section><div id="rustdoc-vars" data-root-path="../../" data-current-crate="kaleidoscope_lexer" data-search-index-js="../../search-index.js" data-search-js="../../search.js"></div><script src="../../main.js"></script></body></html>